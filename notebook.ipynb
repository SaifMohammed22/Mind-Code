{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AggL4nAUk-WL",
        "outputId": "e102dd74-8f2e-49a8-d642-db97b6c89d88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Collecting PySR\n",
            "  Downloading pysr-1.0.0-py3-none-any.whl.metadata (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 kB\u001b[0m \u001b[31m149.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.0)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: sympy<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from PySR) (1.13.1)\n",
            "Requirement already satisfied: scikit_learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from PySR) (1.5.2)\n",
            "Collecting juliacall==0.9.23 (from PySR)\n",
            "  Downloading juliacall-0.9.23-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from PySR) (8.1.7)\n",
            "Collecting juliapkg~=0.1.8 (from juliacall==0.9.23->PySR)\n",
            "  Downloading juliapkg-0.1.15-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn<2.0.0,>=1.0.0->PySR) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn<2.0.0,>=1.0.0->PySR) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy<2.0.0,>=1.0.0->PySR) (1.3.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Collecting semver~=3.0 (from juliapkg~=0.1.8->juliacall==0.9.23->PySR)\n",
            "  Downloading semver-3.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n",
            "Downloading pysr-1.0.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading juliacall-0.9.23-py3-none-any.whl (12 kB)\n",
            "Downloading juliapkg-0.1.15-py3-none-any.whl (16 kB)\n",
            "Downloading semver-3.0.2-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: semver, juliapkg, juliacall, PySR\n",
            "Successfully installed PySR-1.0.0 juliacall-0.9.23 juliapkg-0.1.15 semver-3.0.2\n"
          ]
        }
      ],
      "source": [
        "pip install pandas numpy tensorflow scipy matplotlib PySR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load your Excel data\n",
        "df = pd.read_excel('data.xlsx')\n",
        "\n",
        "# Preview data\n",
        "print(df.head())\n",
        "\n",
        "# Extract necessary columns\n",
        "# Assuming columns are: Patient ID, Time, Group, MRI Feature 1, MRI Feature 2, PET Feature, Misfolded Protein Concentration\n",
        "time = df['Time'].values\n",
        "group = df['Group'].values\n",
        "mri_feature1 = df['MRI Feature 1'].values\n",
        "mri_feature2 = df['MRI Feature 2'].values\n",
        "pet_feature = df['PET Feature'].values\n",
        "misfolded_concentration = df['Misfolded Protein Concentration'].values\n",
        "\n",
        "# Normalize MRI and PET features\n",
        "scaler = StandardScaler()\n",
        "mri_features = scaler.fit_transform(np.column_stack((mri_feature1, mri_feature2)))\n",
        "pet_features = scaler.fit_transform(pet_feature.reshape(-1, 1))\n",
        "\n",
        "# Prepare time and misfolded concentration data\n",
        "# For PINNs, time (t) will be the input, and misfolded protein concentration (c) will be the output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbCxGd2MlCSC",
        "outputId": "1914fddf-fed1-400e-f2be-41867001fd99"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Subject ID      Time    Group  MRI Feature 1  MRI Feature 2  PET Feature  \\\n",
            "0           1  2.857121  Control      -0.268889       0.399223     0.455888   \n",
            "1           1  3.748706  Control      -1.106526       0.647196     2.165002   \n",
            "2           1  5.833688  Control       2.573360      -0.483186    -0.643518   \n",
            "3           1  7.460449  Control       0.059218       1.573987     0.927840   \n",
            "4           1  9.621725  Control       0.013929      -1.225766     0.057013   \n",
            "\n",
            "   Misfolded Protein Concentration  \n",
            "0                         0.483987  \n",
            "1                         0.567134  \n",
            "2                         0.521320  \n",
            "3                         0.424803  \n",
            "4                         0.468095  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "# Define a simple neural network model for c(t)\n",
        "def create_pinn_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=(1,)))  # Time as input\n",
        "    model.add(layers.Dense(50, activation='tanh'))\n",
        "    model.add(layers.Dense(50, activation='tanh'))\n",
        "    model.add(layers.Dense(1))  # Output: concentration c(t)\n",
        "    return model\n",
        "\n",
        "# Create the model for c(t)\n",
        "model_c = create_pinn_model()\n",
        "\n",
        "# Define a model for the reaction term f(c)\n",
        "def create_reaction_model():\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=(1,)))  # Misfolded protein concentration c as input\n",
        "    model.add(layers.Dense(50, activation='tanh'))\n",
        "    model.add(layers.Dense(50, activation='tanh'))\n",
        "    model.add(layers.Dense(1))  # Output: reaction term f(c)\n",
        "    return model\n",
        "\n",
        "# Create the model for f(c)\n",
        "model_f = create_reaction_model()\n",
        "\n",
        "# Combine the models into a joint loss function\n",
        "def pinn_loss(model_c, model_f, t, c_data):\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        tape.watch(t)\n",
        "        c_pred = model_c(t)\n",
        "        f_pred = model_f(c_pred)\n",
        "        dc_dt = tape.gradient(c_pred, t)\n",
        "\n",
        "    # Loss terms\n",
        "    loss_data = tf.reduce_mean(tf.square(c_pred - c_data))  # Data loss\n",
        "    loss_residual = tf.reduce_mean(tf.square(dc_dt - f_pred))  # Residuals of the PDE\n",
        "    total_loss = loss_data + loss_residual\n",
        "    return total_loss\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "# Training loop (simplified)\n",
        "for epoch in range(10000):  # You can adjust the number of epochs\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        # Convert time into tensorflow tensor\n",
        "        t_tensor = tf.convert_to_tensor(time.reshape(-1, 1), dtype=tf.float32)\n",
        "        c_tensor = tf.convert_to_tensor(misfolded_concentration, dtype=tf.float32)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = pinn_loss(model_c, model_f, t_tensor, c_tensor)\n",
        "\n",
        "    optimizer_c = tf.keras.optimizers.Adam()  # For model_c\n",
        "    optimizer_f = tf.keras.optimizers.Adam()  # For model_f\n",
        "\n",
        "    # Perform gradient descent\n",
        "    grads_c = tape.gradient(loss, model_c.trainable_variables)\n",
        "    optimizer_c.apply_gradients(zip(grads_c, model_c.trainable_variables))\n",
        "\n",
        "    # Apply gradients for model_f (with the new optimizer)\n",
        "    grads_f = tape.gradient(loss, model_f.trainable_variables)\n",
        "    optimizer_f.apply_gradients(zip(grads_f, model_f.trainable_variables))\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss.numpy()}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9IhbwrZmmXWn",
        "outputId": "235e0009-c8dd-454f-9f9d-bb2d745f8bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Calling GradientTape.gradient on a persistent tape inside its context is significantly less efficient than calling it outside the context (it causes the gradient ops to be recorded on the tape, leading to increased CPU and memory usage). Only call GradientTape.gradient inside the context if you actually want to trace the gradient in order to compute higher order derivatives.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.5466825366020203\n",
            "Epoch 1000, Loss: 0.28345414996147156\n",
            "Epoch 2000, Loss: 0.27875739336013794\n",
            "Epoch 3000, Loss: 0.2765740752220154\n",
            "Epoch 4000, Loss: 0.2753537893295288\n",
            "Epoch 5000, Loss: 0.27460387349128723\n",
            "Epoch 6000, Loss: 0.27417609095573425\n",
            "Epoch 7000, Loss: 0.27388057112693787\n",
            "Epoch 8000, Loss: 0.27368101477622986\n",
            "Epoch 9000, Loss: 0.2735513746738434\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pysr\n",
        "\n",
        "# Extract the predicted f(c) from the PINNs model\n",
        "f_predictions = model_f.predict(misfolded_concentration.reshape(-1, 1))\n",
        "\n",
        "# Symbolic regression using PySR\n",
        "model = pysr.PySRRegressor(\n",
        "    unary_operators=[\"sin\", \"cos\", \"log\", \"exp\", \"sqrt\"],\n",
        "    binary_operators=[\"+\", \"-\", \"*\", \"/\", \"**\"],\n",
        "    niterations=1000,  # Adjust the number of iterations\n",
        "    # This is optional: You can use a limit for complexity or other parameters\n",
        ")\n",
        "\n",
        "# Fit symbolic regression model\n",
        "symbolic_model = model.fit(misfolded_concentration.reshape(-1, 1), f_predictions)\n",
        "\n",
        "# Get the symbolic expression of f(c)\n",
        "print(\"Discovered symbolic expression for f(c):\")\n",
        "print(symbolic_model)\n"
      ],
      "metadata": {
        "id": "ICNpsvNVmhAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the performance of the symbolic regression model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Get predictions from symbolic regression\n",
        "f_sym_pred = symbolic_model.predict(misfolded_concentration.reshape(-1, 1))\n",
        "\n",
        "# Calculate the MSE between predicted f(c) and model predictions\n",
        "mse = mean_squared_error(f_predictions, f_sym_pred)\n",
        "print(f'Mean Squared Error of symbolic regression predictions: {mse}')\n"
      ],
      "metadata": {
        "id": "mAzhgE-7mnl0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}